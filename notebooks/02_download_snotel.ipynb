{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from datetime import datetime\n",
    "from metloom.pointdata import SnotelPointData\n",
    "import xarray as xr\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull in polygons of US states from the internet\n",
    "states = gpd.read_file('https://eric.clst.org/assets/wiki/uploads/Stuff/gz_2010_us_040_00_500k.json')\n",
    "# filter to only include Washington and Oregon\n",
    "states_wa = states[states['NAME'].isin(['Washington'])]\n",
    "states_or = states[states['NAME'].isin(['Oregon'])]\n",
    "# explode states_wa and just save the largest one (to avoid problems with multipolygons from islands)\n",
    "states_wa_mainland = states_wa.explode(index_parts=True).sort_values(by='geometry').iloc[-1:]\n",
    "states_or_mainland = states_or.explode(index_parts=True).sort_values(by='geometry').iloc[-1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the variables we will want to grab\n",
    "vrs = [SnotelPointData.ALLOWED_VARIABLES.SWE,\n",
    "       SnotelPointData.ALLOWED_VARIABLES.PRECIPITATION]\n",
    "# create a dataframe from all the points available in Washington\n",
    "wa_points = SnotelPointData.points_from_geometry(states_wa_mainland, vrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe from all the points available in Washington\n",
    "df_wa = wa_points.to_dataframe()\n",
    "# filter to elevations between 3800 and 4200 feet\n",
    "df_wa_filtered = df_wa[(df_wa['geometry'].z > 3800) & (df_wa['geometry'].z < 4200)]\n",
    "# save the filtered dataframe to a geojsonfile\n",
    "df_wa_filtered.to_file('../data/01_raw/snotel_wa_4000ft.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe from all the points available in Oregon\n",
    "or_points = SnotelPointData.points_from_geometry(states_or, vrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe from all the points available in Oregon\n",
    "df_or = or_points.to_dataframe()\n",
    "# filter to elevations between 3800 and 4200 feet\n",
    "df_or_filtered = df_or[(df_or['geometry'].z > 3800) & (df_or['geometry'].z < 4200)]\n",
    "# save the filtered dataframe to a geojsonfile\n",
    "df_or_filtered.to_file('../data/01_raw/snotel_or_4000ft.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to grab the daily data from given variables and a given date range for a specific site with an id and name\n",
    "# we want to return a dataframe\n",
    "def get_daily_data(id, name, vrs, start_date, end_date):\n",
    "    # create a pointdata object for the given site id and name\n",
    "    point = SnotelPointData(id, name)\n",
    "    # get the daily data for the given variables and date range\n",
    "    df = point.get_daily_data(start, end, vrs)\n",
    "    # grab the unique geometry from the df\n",
    "    location = df['geometry'].unique()[0]\n",
    "    # convert this geometry into a tuple\n",
    "    location = (location.x, location.y, location.z)\n",
    "    # remove the geometry from the dataframe\n",
    "    df = df.drop('geometry', axis=1)\n",
    "    # create an xarray dataset from the dataframe\n",
    "    ds = df.to_xarray()\n",
    "    # add the location values as lat, lon, elevation as a variable to the dataset dependent on the site\n",
    "    ds['lat'] = location[1]\n",
    "    ds['lon'] = location[0]\n",
    "    ds['elevation'] = location[2]\n",
    "    return ds\n",
    "\n",
    "# create a function to go through indeces of the dataframe and grab the name and id to pass to the get_daily_data function\n",
    "# then we want to add the returned dataframe and concatenate to an xarray dataset\n",
    "# finally we want to return the dataset\n",
    "def get_daily_data_ds(df, vrs, start_date, end_date):\n",
    "    # create an empty list to append to\n",
    "    ds_list = []\n",
    "    # loop through the index of the dataframe\n",
    "    for i in df.index:\n",
    "        # grab the name and id from the dataframe\n",
    "        name = df.loc[i]['name']\n",
    "        id = df.loc[i]['id']\n",
    "        # pass the name and id to the get_daily_data function and append to the list\n",
    "        ds_list.append(get_daily_data(id, name, vrs, start_date, end_date))\n",
    "    # concatenate the list of dataframes into one xarray dataset\n",
    "    ds = xr.concat(ds_list, dim='site')\n",
    "    # do these steps\n",
    "    # convert SWE to float\n",
    "    ds['SWE'] = ds['SWE'].astype(float)\n",
    "    # convert SWE to centimeters from inches\n",
    "    ds['SWE'] = ds['SWE'] * 2.54\n",
    "    # convert PRECIPITATION to float\n",
    "    ds['PRECIPITATION'] = ds['PRECIPITATION'].astype(float)\n",
    "    # convert PRECIPITATION to centimeters from inches\n",
    "    ds['PRECIPITATION'] = ds['PRECIPITATION'] * 2.54\n",
    "    # remove SWE_units variable\n",
    "    ds = ds.drop('SWE_units')\n",
    "    # add an attribute to SWE of units = 'cm'\n",
    "    ds['SWE'].attrs['units'] = 'cm'\n",
    "    # reove PRECIPITATION_units variable\n",
    "    ds = ds.drop('PRECIPITATION_units')\n",
    "    # add an attribute to PRECIPITATION of units = 'cm'\n",
    "    ds['PRECIPITATION'].attrs['units'] = 'cm'\n",
    "    # get the first value of datasource\n",
    "    datasource = ds['datasource'][0].values[0]\n",
    "    # drop datasource variable\n",
    "    ds = ds.drop('datasource')\n",
    "    # add an attribute to the dataset of datasource\n",
    "    ds.attrs['datasource'] = datasource\n",
    "    \n",
    "    # covert datetime\n",
    "    ds['datetime'] = pd.to_datetime(ds['datetime']).date.astype('datetime64[ns]')\n",
    "    # rename datetime to time\n",
    "    ds = ds.rename({'datetime': 'time'})\n",
    "    # return the dataset\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the start and end dates\n",
    "start = datetime(2014, 10, 1)\n",
    "end = datetime(2018, 9, 30)\n",
    "\n",
    "# grab the results for Washington\n",
    "result_wa = get_daily_data_ds(df_wa_filtered, vrs, start, end)\n",
    "# save the results to a netcdf file\n",
    "result_wa.to_netcdf('../data/01_raw/data_snotel_wa_4000ft.nc')\n",
    "# grab the results for Oregon\n",
    "result_or = get_daily_data_ds(df_or_filtered, vrs, start, end)\n",
    "# save the results to a netcdf file\n",
    "result_or.to_netcdf('../data/01_raw/data_snotel_or_4000ft.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out data where the diff between daily values is greater than 30 cm\n",
    "result_wa_filtered = result_wa.where((result_wa.diff('time') < 30) & (result_wa.diff('time') > -30))\n",
    "# create a function to calculate the day of the water year starting on October 1st\n",
    "\n",
    "# add a day of water year variable\n",
    "# result_wa_filtered['dayofwateryear'] = result_wa_filtered.apply_ufunc(day_of_water_year,result_wa_filtered['time'])\n",
    "# # add a water year variable\n",
    "# result_wa_filtered['wateryear'] = result_wa_filtered['time.year'].where(result_wa_filtered['time.month'] > 9, result_wa_filtered['time.year'] - 1)\n",
    "# result_wa_filtered"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
